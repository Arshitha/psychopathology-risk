{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Project Week: Specificity of Structural Brain Markers of Psychopathology Risk\n",
    "### Data exploration of the ABCD dataset. The final output of this notebook is a clean dataset file for the Linear Mixed Models in R. \n",
    "1. Import libraries\n",
    "1. Gather all the data elements from the ABCD text files\n",
    "1. Specify variables of interest\n",
    "1. Create a dataframe with variables of interest\n",
    "1. Remove duplicates and apply exclusion criteria\n",
    "1. Create addiction variables by combining alcohol and drug abuse pathology\n",
    "1. Count number of children in each parental history psychopathology group \n",
    "1. Save clean dataframe for LMM\n",
    "\n",
    "### 1. Import libraries\n",
    "\n",
    "just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # to read/manipulate/write data from files\n",
    "import numpy as np # to manipulate data/generate random numbers\n",
    "import plotly.express as px # interactive visualizations\n",
    "import seaborn as sns # static visualizations\n",
    "import matplotlib.pyplot as plt # fine tune control over visualizations\n",
    "\n",
    "from pathlib import Path # represent and interact with directories/folders in the operating system\n",
    "from collections import namedtuple # structure data in an easy to consume way\n",
    "\n",
    "import requests # retrieve data from an online source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2. Gather all the data elements from all the txt files\n",
    "\n",
    "The ABCD3 folder contains a number of tab-delimited text files with ABCD data.\n",
    "We will first collect all of these files and then load them into pandas DataFrames\n",
    "to compile and access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory we downloaded the ABCD data to `data_path`\n",
    "data_path = Path(\"/shared/project-psychopathology-risk/inputs/data/dataset1/\")\n",
    "# glob (match) all text files in the `data_path` directory\n",
    "files = sorted(data_path.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "After collecting the files, we need to extract information about\n",
    "the data structures and the data elements.\n",
    "The data structures are the text file names (e.g., `abcd_abcls01`)\n",
    "which indicate the type of data stored inside the text file.\n",
    "The data elements are the column names inside the tab delimited\n",
    "text file.\n",
    "\n",
    "The data structure and data element names are condensed to make working\n",
    "with them programmatically easier, but it is difficult for a human\n",
    "to interpret what `abcd_abcls01` means.\n",
    "So in addition to aggregating data structure and data element names\n",
    "together, we are also collecting their metadata to have a human readable description\n",
    "of their condensed names.\n",
    "\n",
    "The data element metadata is located in the data structure files themselves\n",
    "as the second row of the file, however, the data structure metadata was not downloaded\n",
    "necessitating a query to the NDA website to retrieve the human readable\n",
    "description of the data structure (using `requests`).\n",
    "\n",
    "Finally, since we are only interested in the baseline measures, we need to keep track of\n",
    "what names are given to each event in each of the data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the info in 4 different Python datatypes\n",
    "data_elements = []\n",
    "data_structures = {}\n",
    "event_names = set()\n",
    "StructureInfo = namedtuple(\"StructureInfo\", field_names=[\"description\", \"eventnames\"])\n",
    "\n",
    "for text_file in files:\n",
    "    # Extract data structure from filename\n",
    "    data_structure = Path(text_file).name.split('.txt')[0]\n",
    "    \n",
    "    # Read the data structure and capture all the elements from the file\n",
    "    # Note this could have been done using the data returned from the NDA API\n",
    "    # We are using pandas to read both the first and second rows of the file as the header\n",
    "    # Note: by convention dataframe variables contain `df` in the name.\n",
    "    data_structure_df = pd.read_table(text_file, header=[0, 1], nrows=0)\n",
    "    for data_element, metadata in data_structure_df.columns.values.tolist():\n",
    "        data_elements.append([data_element, metadata, data_structure])\n",
    "\n",
    "    \n",
    "    # (Optional) Retrieve the eventnames in each structure. Some structures were only collected\n",
    "    # at baseline while others were collected at specific or multiple timepoints\n",
    "    events_in_structure = None\n",
    "    if any(['eventname' == data_element for data_element in data_structure_df.columns.levels[0]]):\n",
    "        # Here we are skipping the 2nd row of the file containing description using skiprows\n",
    "        possible_event_names_df = pd.read_table(text_file, skiprows=[1], usecols=['eventname'])\n",
    "        events_in_structure = possible_event_names_df.eventname.unique().tolist()\n",
    "        event_names.update(events_in_structure)\n",
    "\n",
    "    # (Optional) Retrieve the title for the structure using the NDA API\n",
    "    rinfo = requests.get(f\"https://nda.nih.gov/api/datadictionary/datastructure/{data_structure}\").json()\n",
    "    data_structures[data_structure] = StructureInfo(description=rinfo[\"title\"] if \"title\" in rinfo else None,\n",
    "                                                    eventnames=events_in_structure)\n",
    "\n",
    "# Convert to a Pandas dataframe\n",
    "data_elements_df = pd.DataFrame(data_elements, columns=[\"element\", \"description\", \"structure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Uncomment next line to save data elements to a tab-separated file\n",
    "# data_elements_df.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/data_elements.tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Specify variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for dataframe\n",
    "common = ['subjectkey', 'interview_age', 'interview_date', 'eventname', 'sex']\n",
    "nested = ['rel_family_id', 'mri_info_deviceserialnumber', 'site_id_l','acs_raked_propensity_score']\n",
    "puberty = ['pds_p_ss_female_category']\n",
    "\n",
    "#freesurfer subcortical volume in mm^3 of ASEG ROI\n",
    "scvol = ['smri_vol_scs_aal', 'smri_vol_scs_aar', 'smri_vol_scs_amygdalalh', 'smri_vol_scs_amygdalarh', \n",
    "         'smri_vol_scs_caudatelh', 'smri_vol_scs_caudaterh', 'smri_vol_scs_hpuslh', 'smri_vol_scs_hpusrh', \n",
    "         'smri_vol_scs_pallidumlh', 'smri_vol_scs_pallidumrh', 'smri_vol_scs_putamenlh', 'smri_vol_scs_putamenrh',\n",
    "         'smri_vol_scs_tplh', 'smri_vol_scs_tprh', 'smri_vol_scs_intracranialv']\n",
    "\n",
    "# parental psychopathology \n",
    "famhx_moth = ['famhx_ss_moth_prob_dprs_p','famhx_ss_moth_prob_alc_p', 'famhx_ss_moth_prob_dg_p', \n",
    "              'famhx_ss_moth_prob_ma_p', 'famhx_ss_moth_prob_nrv_p']\n",
    "famhx_fath = ['famhx_ss_fath_prob_dprs_p','famhx_ss_fath_prob_alc_p', 'famhx_ss_fath_prob_dg_p', \n",
    "              'famhx_ss_fath_prob_ma_p', 'famhx_ss_fath_prob_nrv_p']\n",
    "famhx_momdad = ['famhx_ss_momdad_dprs_p','famhx_ss_momdad_alc_p', 'famhx_ss_momdad_dg_p', \n",
    "                'famhx_ss_momdad_ma_p', 'famhx_ss_momdad_nrv_p']\n",
    "famhx_parent =['famhx_ss_parent_dprs_p','famhx_ss_parent_alc_p', 'famhx_ss_parent_dg_p', \n",
    "               'famhx_ss_parent_ma_p', 'famhx_ss_parent_nrv_p']\n",
    "# quality control (exclusion criteria)\n",
    "qc = [\"iqc_t1_ok_ser\", \"fsqc_qc\", \"mrif_score\", 'demo_prim', 'famhx_ss_momdad_vs_p']\n",
    "\n",
    "#piagliaccio = [\"demo_race_a_p___10\", \"demo_race_a_p___11\", \"demo_ethn_v2\", \"demo_prnt_marital_v2\", \"demo_prnt_ed_v2\",\n",
    "#              \"demo_comb_income_v2\", \"anthro_1_height_in\", \"ksads_1_842_p\", \"ksads_1_1_t\", \"cbcl_q01_p\", \"cbcl_scr_syn_anxdep_r\"]\n",
    "\n",
    "#freesurfer cortical volume\n",
    "#cortvol = [\"smri_vol_cdk_banksstslh\", \"smri_vol_cdk_banksstsrh\", \"smri_vol_cdk_cdacatelh\", \"smri_vol_cdk_cdacaterh\", \n",
    "#           \"smri_vol_cdk_cdmdfrlh\", \"smri_vol_cdk_cdmdfrrh\", \"smri_vol_cdk_cuneuslh\", \"smri_vol_cdk_cuneusrh\", \n",
    "#           \"smri_vol_cdk_ehinallh\", \"smri_vol_cdk_ehinalrh\", 'smri_vol_cdk_frpolelh', 'smri_vol_cdk_frpolerh', \n",
    "#           'smri_vol_cdk_fusiformlh', 'smri_vol_cdk_fusiformrh', 'smri_vol_cdk_ifpllh', 'smri_vol_cdk_ifplrh', \n",
    "#           'smri_vol_cdk_iftmlh', 'smri_vol_cdk_iftmrh', 'smri_vol_cdk_ihcatelh', 'smri_vol_cdk_ihcaterh',\n",
    "#           'smri_vol_cdk_insulalh', 'smri_vol_cdk_insularh','smri_vol_cdk_linguallh', 'smri_vol_cdk_lingualrh', \n",
    "#           'smri_vol_cdk_lobfrlh', 'smri_vol_cdk_lobfrrh', 'smri_vol_cdk_locclh', 'smri_vol_cdk_loccrh',\n",
    "#           'smri_vol_cdk_mdtmlh', 'smri_vol_cdk_mdtmrh', 'smri_vol_cdk_mobfrlh', 'smri_vol_cdk_mobfrrh',\n",
    "#           'smri_vol_cdk_paracnlh', 'smri_vol_cdk_paracnrh', 'smri_vol_cdk_parahpallh', 'smri_vol_cdk_parahpalrh', \n",
    "#           'smri_vol_cdk_parsobislh', 'smri_vol_cdk_parsobisrh', 'smri_vol_cdk_parsopclh', 'smri_vol_cdk_parsopcrh', \n",
    "#           'smri_vol_cdk_parstgrislh', 'smri_vol_cdk_parstgrisrh', 'smri_vol_cdk_pclh', 'smri_vol_cdk_pcrh', \n",
    "#           'smri_vol_cdk_pericclh', 'smri_vol_cdk_periccrh', 'smri_vol_cdk_postcnlh', 'smri_vol_cdk_postcnrh', \n",
    "#           'smri_vol_cdk_precnlh', 'smri_vol_cdk_precnrh', 'smri_vol_cdk_ptcatelh', 'smri_vol_cdk_ptcaterh', \n",
    "#           'smri_vol_cdk_rracatelh', 'smri_vol_cdk_rracaterh', 'smri_vol_cdk_rrmdfrlh', 'smri_vol_cdk_rrmdfrrh', \n",
    "#           'smri_vol_cdk_smlh', 'smri_vol_cdk_smrh', 'smri_vol_cdk_sufrlh', 'smri_vol_cdk_sufrrh', \n",
    "#           'smri_vol_cdk_supllh', 'smri_vol_cdk_suplrh', 'smri_vol_cdk_sutmlh', 'smri_vol_cdk_sutmrh', \n",
    "#           'smri_vol_cdk_tmpolelh', 'smri_vol_cdk_tmpolerh', 'smri_vol_cdk_trvtmlh', 'smri_vol_cdk_trvtmrh']\n",
    "\n",
    "data_elements_of_interest = nested + puberty + scvol + famhx_moth + famhx_fath + famhx_momdad + famhx_parent + qc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the data structures that contain the data elements\n",
    "\n",
    "The `data_elements_of_interest` above tell us what data elements we wish to analyze,\n",
    "but they do not provide information about which data structures the data elements are located.\n",
    "But do not fret, we created `data_elements_df` to match data elements with their respective data structures,\n",
    "giving us the ability to find the data structure associated with each data element of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acspsw03': ['rel_family_id', 'acs_raked_propensity_score'],\n",
       " 'abcd_mri01': ['mri_info_deviceserialnumber'],\n",
       " 'abcd_lt01': ['site_id_l'],\n",
       " 'abcd_ssphp01': ['pds_p_ss_female_category'],\n",
       " 'abcd_smrip201': ['smri_vol_scs_aal',\n",
       "  'smri_vol_scs_aar',\n",
       "  'smri_vol_scs_amygdalalh',\n",
       "  'smri_vol_scs_amygdalarh',\n",
       "  'smri_vol_scs_caudatelh',\n",
       "  'smri_vol_scs_caudaterh',\n",
       "  'smri_vol_scs_hpuslh',\n",
       "  'smri_vol_scs_hpusrh',\n",
       "  'smri_vol_scs_pallidumlh',\n",
       "  'smri_vol_scs_pallidumrh',\n",
       "  'smri_vol_scs_putamenlh',\n",
       "  'smri_vol_scs_putamenrh',\n",
       "  'smri_vol_scs_tplh',\n",
       "  'smri_vol_scs_tprh',\n",
       "  'smri_vol_scs_intracranialv'],\n",
       " 'abcd_fhxssp01': ['famhx_ss_moth_prob_dprs_p',\n",
       "  'famhx_ss_moth_prob_alc_p',\n",
       "  'famhx_ss_moth_prob_dg_p',\n",
       "  'famhx_ss_moth_prob_ma_p',\n",
       "  'famhx_ss_moth_prob_nrv_p',\n",
       "  'famhx_ss_fath_prob_dprs_p',\n",
       "  'famhx_ss_fath_prob_alc_p',\n",
       "  'famhx_ss_fath_prob_dg_p',\n",
       "  'famhx_ss_fath_prob_ma_p',\n",
       "  'famhx_ss_fath_prob_nrv_p',\n",
       "  'famhx_ss_momdad_dprs_p',\n",
       "  'famhx_ss_momdad_alc_p',\n",
       "  'famhx_ss_momdad_dg_p',\n",
       "  'famhx_ss_momdad_ma_p',\n",
       "  'famhx_ss_momdad_nrv_p',\n",
       "  'famhx_ss_parent_dprs_p',\n",
       "  'famhx_ss_parent_alc_p',\n",
       "  'famhx_ss_parent_dg_p',\n",
       "  'famhx_ss_parent_ma_p',\n",
       "  'famhx_ss_parent_nrv_p',\n",
       "  'famhx_ss_momdad_vs_p'],\n",
       " 'mriqcrp102': ['iqc_t1_ok_ser'],\n",
       " 'freesqc01': ['fsqc_qc'],\n",
       " 'abcd_mrfindings02': ['mrif_score'],\n",
       " 'pdem02': ['demo_prim']}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures2read = {}\n",
    "for element in data_elements_of_interest:\n",
    "    item = data_elements_df.query(f\"element == '{element}'\").structure.values[0]\n",
    "    if item not in structures2read:\n",
    "        structures2read[item] = []\n",
    "    structures2read[item].append(element)\n",
    "structures2read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4. Create a dataframe with the variables of interest\n",
    "Now we have the data structures that contain the data elements of interest in `structures2read`,\n",
    "a dictionary whose keys are the data structures and whose values are the data elements of interest\n",
    "within that data structure.\n",
    "Here we load the data structures into python with the variables (elements) of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = None\n",
    "for structure, elements in structures2read.items():\n",
    "    data_structure_filtered_df = pd.read_table(data_path / f\"{structure}.txt\", skiprows=[1], low_memory=False, usecols=common + elements)\n",
    "    data_structure_filtered_df = data_structure_filtered_df.query(\"eventname == 'baseline_year_1_arm_1'\")\n",
    "    if all_df is None:\n",
    "        all_df =  data_structure_filtered_df[[\"subjectkey\", \"interview_date\", \"interview_age\", \"sex\", \"eventname\"] + elements]\n",
    "    else:\n",
    "        all_df = all_df.merge( data_structure_filtered_df[['subjectkey'] + elements], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11883, 50), (11878,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape, all_df.subjectkey.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 5. Remove duplicates and apply exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11878, 50), (11878,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "all_df = all_df.drop_duplicates(subset=['subjectkey'])\n",
    "all_df.shape, all_df.subjectkey.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11878, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy dataframe/backup\n",
    "df1 = all_df.copy()\n",
    "df1.shape #output is number of children x number of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Exclusion criteria \n",
    "1. iqc_t1_ok_ser: quality T1 scans == 0 \n",
    "1. fsqc_qc: quality control freesurfer outputs. 0 = reject; 1 = accept\n",
    "1. mrif_score: incidental findings from neuroradiological read of the sMRI. 0 = reject; 1 = accept\n",
    "1. demo_prim: if parental report was not based on biological parent. Exclude value >2\n",
    "1. If either parent endorsed visions of others spying/plotting problems. Exclude value == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count subjects that will be excluded per variable for method section\n",
    "(df1['iqc_t1_ok_ser'] == 0).astype(int).sum(axis=0)        #40 subjects\n",
    "(df1['fsqc_qc'] == 0).astype(int).sum(axis=0)              #475 subjects\n",
    "(df1['mrif_score'] ==0).astype(int).sum(axis=0)            #47\n",
    "(df1['demo_prim'] > 2).astype(int).sum(axis=0)             #560 subjects\n",
    "(df1['famhx_ss_momdad_vs_p'] == 1).astype(int).sum(axis=0) #241 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10589, 50)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove rows that fullfill at least 1 of the exclusion criteria\n",
    "indexNames = df1[(df1['iqc_t1_ok_ser'] == 0) | (df1['fsqc_qc'] == 0) | (df1['mrif_score'] == 0) | (df1['demo_prim'] > 2) | (df1['famhx_ss_momdad_vs_p'] == 1)].index   \n",
    "df1.drop(indexNames , inplace=True)    # Delete these row indexes from dataFrame\n",
    "df1.shape #output = number of children x number of variables\n",
    "\n",
    "#copy/backup\n",
    "df2 = df1.copy()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 6. Create addiction varibles based on alcohol and drug abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['famhx_ss_moth_addiction'] = np.where((df2.famhx_ss_moth_prob_alc_p == 1) | (df2.famhx_ss_moth_prob_dg_p == 1), 1.0, 0.0)\n",
    "df2['famhx_ss_fath_addiction'] = np.where((df2.famhx_ss_fath_prob_alc_p == 1) | (df2.famhx_ss_fath_prob_dg_p == 1), 1.0, 0.0)\n",
    "df2['famhx_ss_momdad_addiction'] = np.where((df2.famhx_ss_momdad_alc_p == 1) | (df2.famhx_ss_momdad_dg_p == 1), 1.0, 0.0)\n",
    "\n",
    "# Not sure how to code the famhx_ss_parent_addiction with 6 different values (in particularly the negative values) \n",
    "# For now I created a binary variable that shows whether both parents have a problem or not.\n",
    "df2['famhx_ss_parent_addiction_bin'] = np.where((df2.famhx_ss_parent_alc_p == 3) | (df2.famhx_ss_parent_dg_p == 3), 1.0, 0.0) #both parent have addiction problem (0 = no, 1 = yes)\n",
    "df2['famhx_ss_parent_dprs_bin'] = np.where((df2.famhx_ss_parent_dprs_p == 3), 1.0, 0.0)\n",
    "df2['famhx_ss_parent_ma_bin'] = np.where((df2.famhx_ss_parent_ma_p == 3), 1.0, 0.0)\n",
    "df2['famhx_ss_parent_nrv_bin'] = np.where((df2.famhx_ss_parent_nrv_p == 3), 1.0, 0.0)\n",
    "\n",
    "#explore addiction counts\n",
    "s1 = df2.groupby(['famhx_ss_moth_addiction', 'famhx_ss_moth_prob_alc_p', 'famhx_ss_moth_prob_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction mother\n",
    "s2 = df2.groupby(['famhx_ss_fath_addiction', 'famhx_ss_fath_prob_alc_p', 'famhx_ss_fath_prob_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction father\n",
    "s3 = df2.groupby(['famhx_ss_momdad_addiction', 'famhx_ss_momdad_alc_p', 'famhx_ss_momdad_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction either mother or father\n",
    "s4 = df2.groupby(['famhx_ss_parent_addiction_bin', 'famhx_ss_parent_alc_p', 'famhx_ss_parent_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction both parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_moth_addiction</th>\n",
       "      <th>famhx_ss_moth_prob_alc_p</th>\n",
       "      <th>famhx_ss_moth_prob_dg_p</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   famhx_ss_moth_addiction  famhx_ss_moth_prob_alc_p  famhx_ss_moth_prob_dg_p  \\\n",
       "0                      0.0                       0.0                      0.0   \n",
       "1                      1.0                       0.0                      1.0   \n",
       "2                      1.0                       1.0                      0.0   \n",
       "3                      1.0                       1.0                      1.0   \n",
       "\n",
       "   count  \n",
       "0   7706  \n",
       "1   2079  \n",
       "2    147  \n",
       "3    165  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 #view count table - insert s1-s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data - note that this file contains many variables that are not needed for the LMM. \n",
    "#copy/backup and remove variable columns we do not need anymore including 'famhx_ss_*_alc_p', 'famhx_ss_*_dg_p'])\n",
    "df3 = df2.copy()\n",
    "df3.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/PsychRisk2.tsv\", sep=\"\\t\", index=None)# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Exploration number of children in each parental history psychopathology group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are no longer needed including alcohol and drug abuse history and quality control variables\n",
    "df3 = df3.drop(columns=['famhx_ss_moth_prob_alc_p', 'famhx_ss_fath_prob_alc_p', 'famhx_ss_momdad_alc_p', 'famhx_ss_parent_alc_p', \n",
    "                  'famhx_ss_moth_prob_dg_p', 'famhx_ss_fath_prob_dg_p', 'famhx_ss_momdad_dg_p', 'famhx_ss_parent_dg_p',\n",
    "                 'famhx_ss_momdad_vs_p', 'iqc_t1_ok_ser', 'fsqc_qc', 'demo_prim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_moth_prob_dprs_p</th>\n",
       "      <th>famhx_ss_moth_prob_ma_p</th>\n",
       "      <th>famhx_ss_moth_prob_nrv_p</th>\n",
       "      <th>famhx_ss_fath_prob_dprs_p</th>\n",
       "      <th>famhx_ss_fath_prob_ma_p</th>\n",
       "      <th>famhx_ss_fath_prob_nrv_p</th>\n",
       "      <th>famhx_ss_momdad_dprs_p</th>\n",
       "      <th>famhx_ss_momdad_ma_p</th>\n",
       "      <th>famhx_ss_momdad_nrv_p</th>\n",
       "      <th>famhx_ss_parent_dprs_p</th>\n",
       "      <th>famhx_ss_parent_ma_p</th>\n",
       "      <th>famhx_ss_parent_nrv_p</th>\n",
       "      <th>famhx_ss_moth_addiction</th>\n",
       "      <th>famhx_ss_fath_addiction</th>\n",
       "      <th>famhx_ss_momdad_addiction</th>\n",
       "      <th>famhx_ss_parent_addiction_bin</th>\n",
       "      <th>famhx_ss_parent_dprs_bin</th>\n",
       "      <th>famhx_ss_parent_ma_bin</th>\n",
       "      <th>famhx_ss_parent_nrv_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10154.0</td>\n",
       "      <td>10098.0</td>\n",
       "      <td>9443.0</td>\n",
       "      <td>9527.0</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>9714.0</td>\n",
       "      <td>9421.0</td>\n",
       "      <td>9866.0</td>\n",
       "      <td>9114.0</td>\n",
       "      <td>9421</td>\n",
       "      <td>9866</td>\n",
       "      <td>9114</td>\n",
       "      <td>8160.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>6873.0</td>\n",
       "      <td>9880.0</td>\n",
       "      <td>10465.0</td>\n",
       "      <td>10570.0</td>\n",
       "      <td>10433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>240.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>662</td>\n",
       "      <td>200</td>\n",
       "      <td>285</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>3716.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>144</td>\n",
       "      <td>593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      famhx_ss_moth_prob_dprs_p  famhx_ss_moth_prob_ma_p  \\\n",
       "-2.0                        NaN                      NaN   \n",
       "-1.0                        NaN                      NaN   \n",
       " 0.0                    10154.0                  10098.0   \n",
       " 1.0                      240.0                    181.0   \n",
       " 2.0                        NaN                      NaN   \n",
       " 3.0                        NaN                      NaN   \n",
       "\n",
       "      famhx_ss_moth_prob_nrv_p  famhx_ss_fath_prob_dprs_p  \\\n",
       "-2.0                       NaN                        NaN   \n",
       "-1.0                       NaN                        NaN   \n",
       " 0.0                    9443.0                     9527.0   \n",
       " 1.0                     814.0                      795.0   \n",
       " 2.0                       NaN                        NaN   \n",
       " 3.0                       NaN                        NaN   \n",
       "\n",
       "      famhx_ss_fath_prob_ma_p  famhx_ss_fath_prob_nrv_p  \\\n",
       "-2.0                      NaN                       NaN   \n",
       "-1.0                      NaN                       NaN   \n",
       " 0.0                  10012.0                    9714.0   \n",
       " 1.0                    225.0                     444.0   \n",
       " 2.0                      NaN                       NaN   \n",
       " 3.0                      NaN                       NaN   \n",
       "\n",
       "      famhx_ss_momdad_dprs_p  famhx_ss_momdad_ma_p  famhx_ss_momdad_nrv_p  \\\n",
       "-2.0                     NaN                   NaN                    NaN   \n",
       "-1.0                     NaN                   NaN                    NaN   \n",
       " 0.0                  9421.0                9866.0                 9114.0   \n",
       " 1.0                   911.0                 387.0                 1102.0   \n",
       " 2.0                     NaN                   NaN                    NaN   \n",
       " 3.0                     NaN                   NaN                    NaN   \n",
       "\n",
       "      famhx_ss_parent_dprs_p  famhx_ss_parent_ma_p  famhx_ss_parent_nrv_p  \\\n",
       "-2.0                       9                     6                      3   \n",
       "-1.0                      14                    18                     65   \n",
       " 0.0                    9421                  9866                   9114   \n",
       " 1.0                     662                   200                    285   \n",
       " 2.0                     102                   144                    593   \n",
       " 3.0                     124                    19                    156   \n",
       "\n",
       "      famhx_ss_moth_addiction  famhx_ss_fath_addiction  \\\n",
       "-2.0                      NaN                      NaN   \n",
       "-1.0                      NaN                      NaN   \n",
       " 0.0                   8160.0                   8400.0   \n",
       " 1.0                   2429.0                   2189.0   \n",
       " 2.0                      NaN                      NaN   \n",
       " 3.0                      NaN                      NaN   \n",
       "\n",
       "      famhx_ss_momdad_addiction  famhx_ss_parent_addiction_bin  \\\n",
       "-2.0                        NaN                            NaN   \n",
       "-1.0                        NaN                            NaN   \n",
       " 0.0                     6873.0                         9880.0   \n",
       " 1.0                     3716.0                          709.0   \n",
       " 2.0                        NaN                            NaN   \n",
       " 3.0                        NaN                            NaN   \n",
       "\n",
       "      famhx_ss_parent_dprs_bin  famhx_ss_parent_ma_bin  \\\n",
       "-2.0                       NaN                     NaN   \n",
       "-1.0                       NaN                     NaN   \n",
       " 0.0                   10465.0                 10570.0   \n",
       " 1.0                     124.0                    19.0   \n",
       " 2.0                       NaN                     NaN   \n",
       " 3.0                       NaN                     NaN   \n",
       "\n",
       "      famhx_ss_parent_nrv_bin  \n",
       "-2.0                      NaN  \n",
       "-1.0                      NaN  \n",
       " 0.0                  10433.0  \n",
       " 1.0                    156.0  \n",
       " 2.0                      NaN  \n",
       " 3.0                      NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count data\n",
    "filter_col = [col for col in df3 if col.startswith('famhx_')]\n",
    "fh_df = df3[filter_col] #create dataframe with parental history psychopathology variables          \n",
    "fh_df.apply(pd.Series.value_counts)        #counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count data and comorbidities\n",
    "t1 = fh_df.groupby(['famhx_ss_moth_prob_dprs_p', 'famhx_ss_moth_addiction','famhx_ss_moth_prob_ma_p', 'famhx_ss_moth_prob_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t2 = fh_df.groupby(['famhx_ss_fath_prob_dprs_p', 'famhx_ss_fath_addiction','famhx_ss_fath_prob_ma_p', 'famhx_ss_fath_prob_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t3 = fh_df.groupby(['famhx_ss_momdad_dprs_p', 'famhx_ss_momdad_addiction','famhx_ss_momdad_ma_p', 'famhx_ss_momdad_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t4 = fh_df.groupby(['famhx_ss_parent_dprs_p', 'famhx_ss_parent_addiction_bin','famhx_ss_parent_ma_p', 'famhx_ss_parent_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "\n",
    "#uncomment to save file to .csv\n",
    "#t1.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_mother.csv')\n",
    "#t2.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_father.csv')\n",
    "#t3.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_momdad.csv')\n",
    "#t4.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_parents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_momdad_dprs_p</th>\n",
       "      <th>famhx_ss_momdad_addiction</th>\n",
       "      <th>famhx_ss_momdad_ma_p</th>\n",
       "      <th>famhx_ss_momdad_nrv_p</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    famhx_ss_momdad_dprs_p  famhx_ss_momdad_addiction  famhx_ss_momdad_ma_p  \\\n",
       "0                      0.0                        0.0                   0.0   \n",
       "1                      0.0                        0.0                   0.0   \n",
       "2                      0.0                        0.0                   1.0   \n",
       "3                      0.0                        0.0                   1.0   \n",
       "4                      0.0                        1.0                   0.0   \n",
       "5                      0.0                        1.0                   0.0   \n",
       "6                      0.0                        1.0                   1.0   \n",
       "7                      0.0                        1.0                   1.0   \n",
       "8                      1.0                        0.0                   0.0   \n",
       "9                      1.0                        0.0                   0.0   \n",
       "10                     1.0                        0.0                   1.0   \n",
       "11                     1.0                        0.0                   1.0   \n",
       "12                     1.0                        1.0                   0.0   \n",
       "13                     1.0                        1.0                   0.0   \n",
       "14                     1.0                        1.0                   1.0   \n",
       "15                     1.0                        1.0                   1.0   \n",
       "\n",
       "    famhx_ss_momdad_nrv_p  count  \n",
       "0                     0.0   6024  \n",
       "1                     1.0    225  \n",
       "2                     0.0     34  \n",
       "3                     1.0      9  \n",
       "4                     0.0   2104  \n",
       "5                     1.0    510  \n",
       "6                     0.0     92  \n",
       "7                     1.0     88  \n",
       "8                     0.0    176  \n",
       "9                     1.0     10  \n",
       "10                    0.0      6  \n",
       "11                    1.0      2  \n",
       "12                    0.0    359  \n",
       "13                    1.0    132  \n",
       "14                    0.0     75  \n",
       "15                    1.0     60  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 #print table t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save clean dataframe for Linear Mixed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/PsychRisk_clean2.tsv\", sep=\"\\t\", index=None) #input LMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

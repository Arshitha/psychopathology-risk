{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Project Week: Specificity of Structural Brain Markers of Psychopathology Risk\n",
    "### Data exploration of the ABCD dataset. The final output of this notebook is a clean dataset file for the Linear Mixed Models in R. \n",
    "1. Import libraries\n",
    "1. Gather all the data elements from the ABCD text files\n",
    "1. Specify variables of interest\n",
    "1. Create a dataframe with variables of interest\n",
    "1. Remove duplicates and apply exclusion criteria\n",
    "1. Create addiction variables by combining alcohol and drug abuse pathology\n",
    "1. Count number of children in each parental history psychopathology group \n",
    "1. Save clean dataframe for LMM\n",
    "\n",
    "### 1. Import libraries\n",
    "\n",
    "just checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # to read/manipulate/write data from files\n",
    "import numpy as np # to manipulate data/generate random numbers\n",
    "import plotly.express as px # interactive visualizations\n",
    "import seaborn as sns # static visualizations\n",
    "import matplotlib.pyplot as plt # fine tune control over visualizations\n",
    "\n",
    "from pathlib import Path # represent and interact with directories/folders in the operating system\n",
    "from collections import namedtuple # structure data in an easy to consume way\n",
    "\n",
    "import requests # retrieve data from an online source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 2. Gather all the data elements from all the txt files\n",
    "\n",
    "The ABCD3 folder contains a number of tab-delimited text files with ABCD data.\n",
    "We will first collect all of these files and then load them into pandas DataFrames\n",
    "to compile and access the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save directory we downloaded the ABCD data to `data_path`\n",
    "data_path = Path(\"/shared/project-psychopathology-risk/inputs/data/dataset1/\")\n",
    "# glob (match) all text files in the `data_path` directory\n",
    "files = sorted(data_path.glob(\"*.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "After collecting the files, we need to extract information about\n",
    "the data structures and the data elements.\n",
    "The data structures are the text file names (e.g., `abcd_abcls01`)\n",
    "which indicate the type of data stored inside the text file.\n",
    "The data elements are the column names inside the tab delimited\n",
    "text file.\n",
    "\n",
    "The data structure and data element names are condensed to make working\n",
    "with them programmatically easier, but it is difficult for a human\n",
    "to interpret what `abcd_abcls01` means.\n",
    "So in addition to aggregating data structure and data element names\n",
    "together, we are also collecting their metadata to have a human readable description\n",
    "of their condensed names.\n",
    "\n",
    "The data element metadata is located in the data structure files themselves\n",
    "as the second row of the file, however, the data structure metadata was not downloaded\n",
    "necessitating a query to the NDA website to retrieve the human readable\n",
    "description of the data structure (using `requests`).\n",
    "\n",
    "Finally, since we are only interested in the baseline measures, we need to keep track of\n",
    "what names are given to each event in each of the data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We store the info in 4 different Python datatypes\n",
    "data_elements = []\n",
    "data_structures = {}\n",
    "event_names = set()\n",
    "StructureInfo = namedtuple(\"StructureInfo\", field_names=[\"description\", \"eventnames\"])\n",
    "\n",
    "for text_file in files:\n",
    "    # Extract data structure from filename\n",
    "    data_structure = Path(text_file).name.split('.txt')[0]\n",
    "    \n",
    "    # Read the data structure and capture all the elements from the file\n",
    "    # Note this could have been done using the data returned from the NDA API\n",
    "    # We are using pandas to read both the first and second rows of the file as the header\n",
    "    # Note: by convention dataframe variables contain `df` in the name.\n",
    "    data_structure_df = pd.read_table(text_file, header=[0, 1], nrows=0)\n",
    "    for data_element, metadata in data_structure_df.columns.values.tolist():\n",
    "        data_elements.append([data_element, metadata, data_structure])\n",
    "\n",
    "    \n",
    "    # (Optional) Retrieve the eventnames in each structure. Some structures were only collected\n",
    "    # at baseline while others were collected at specific or multiple timepoints\n",
    "    events_in_structure = None\n",
    "    if any(['eventname' == data_element for data_element in data_structure_df.columns.levels[0]]):\n",
    "        # Here we are skipping the 2nd row of the file containing description using skiprows\n",
    "        possible_event_names_df = pd.read_table(text_file, skiprows=[1], usecols=['eventname'])\n",
    "        events_in_structure = possible_event_names_df.eventname.unique().tolist()\n",
    "        event_names.update(events_in_structure)\n",
    "\n",
    "    # (Optional) Retrieve the title for the structure using the NDA API\n",
    "    rinfo = requests.get(f\"https://nda.nih.gov/api/datadictionary/datastructure/{data_structure}\").json()\n",
    "    data_structures[data_structure] = StructureInfo(description=rinfo[\"title\"] if \"title\" in rinfo else None,\n",
    "                                                    eventnames=events_in_structure)\n",
    "\n",
    "# Convert to a Pandas dataframe\n",
    "data_elements_df = pd.DataFrame(data_elements, columns=[\"element\", \"description\", \"structure\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "## Uncomment next line to save data elements to a tab-separated file\n",
    "# data_elements_df.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/data_elements.tsv\", sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Specify variables of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for dataframe\n",
    "common = ['subjectkey', 'interview_age', 'interview_date', 'eventname', 'sex']\n",
    "nested = ['rel_family_id', 'mri_info_deviceserialnumber', 'site_id_l','acs_raked_propensity_score']\n",
    "puberty = ['pds_p_ss_female_category', 'pds_p_ss_male_category']\n",
    "\n",
    "#freesurfer subcortical volume in mm^3 of ASEG ROI\n",
    "scvol = ['smri_vol_scs_aal', 'smri_vol_scs_aar', 'smri_vol_scs_amygdalalh', 'smri_vol_scs_amygdalarh', \n",
    "         'smri_vol_scs_caudatelh', 'smri_vol_scs_caudaterh', 'smri_vol_scs_hpuslh', 'smri_vol_scs_hpusrh', \n",
    "         'smri_vol_scs_pallidumlh', 'smri_vol_scs_pallidumrh', 'smri_vol_scs_putamenlh', 'smri_vol_scs_putamenrh',\n",
    "         'smri_vol_scs_tplh', 'smri_vol_scs_tprh', 'smri_vol_scs_intracranialv', 'smri_vol_scs_subcorticalgv']\n",
    "\n",
    "# parental psychopathology \n",
    "famhx_moth = ['famhx_ss_moth_prob_dprs_p','famhx_ss_moth_prob_alc_p', 'famhx_ss_moth_prob_dg_p', \n",
    "              'famhx_ss_moth_prob_ma_p', 'famhx_ss_moth_prob_nrv_p']\n",
    "famhx_fath = ['famhx_ss_fath_prob_dprs_p','famhx_ss_fath_prob_alc_p', 'famhx_ss_fath_prob_dg_p', \n",
    "              'famhx_ss_fath_prob_ma_p', 'famhx_ss_fath_prob_nrv_p']\n",
    "famhx_momdad = ['famhx_ss_momdad_dprs_p','famhx_ss_momdad_alc_p', 'famhx_ss_momdad_dg_p', \n",
    "                'famhx_ss_momdad_ma_p', 'famhx_ss_momdad_nrv_p']\n",
    "famhx_parent =['famhx_ss_parent_dprs_p','famhx_ss_parent_alc_p', 'famhx_ss_parent_dg_p', \n",
    "               'famhx_ss_parent_ma_p', 'famhx_ss_parent_nrv_p']\n",
    "# quality control (exclusion criteria)\n",
    "qc = [\"iqc_t1_ok_ser\", \"fsqc_qc\", \"mrif_score\", 'demo_prim', 'famhx_ss_momdad_vs_p']\n",
    "\n",
    "piagliaccio = [\"race_ethnicity\", \"demo_comb_income_v2\", \"demo_prnt_ed_v2\"]\n",
    "#pagliaccio2 = [\"demo_prnt_marital_v2\", \"anthro_1_height_in\", \"ksads_1_842_p\", \"ksads_1_1_t\", \"cbcl_q01_p\", \"cbcl_scr_syn_anxdep_r\"]\n",
    "\n",
    "#freesurfer cortical volume\n",
    "cortvol = [\"smri_vol_cdk_banksstslh\", \"smri_vol_cdk_banksstsrh\", \"smri_vol_cdk_cdacatelh\", \"smri_vol_cdk_cdacaterh\", \n",
    "           \"smri_vol_cdk_cdmdfrlh\", \"smri_vol_cdk_cdmdfrrh\", \"smri_vol_cdk_cuneuslh\", \"smri_vol_cdk_cuneusrh\", \n",
    "           \"smri_vol_cdk_ehinallh\", \"smri_vol_cdk_ehinalrh\", 'smri_vol_cdk_frpolelh', 'smri_vol_cdk_frpolerh', \n",
    "           'smri_vol_cdk_fusiformlh', 'smri_vol_cdk_fusiformrh', 'smri_vol_cdk_ifpllh', 'smri_vol_cdk_ifplrh', \n",
    "           'smri_vol_cdk_iftmlh', 'smri_vol_cdk_iftmrh', 'smri_vol_cdk_ihcatelh', 'smri_vol_cdk_ihcaterh',\n",
    "           'smri_vol_cdk_insulalh', 'smri_vol_cdk_insularh','smri_vol_cdk_linguallh', 'smri_vol_cdk_lingualrh', \n",
    "           'smri_vol_cdk_lobfrlh', 'smri_vol_cdk_lobfrrh', 'smri_vol_cdk_locclh', 'smri_vol_cdk_loccrh',\n",
    "           'smri_vol_cdk_mdtmlh', 'smri_vol_cdk_mdtmrh', 'smri_vol_cdk_mobfrlh', 'smri_vol_cdk_mobfrrh',\n",
    "           'smri_vol_cdk_paracnlh', 'smri_vol_cdk_paracnrh', 'smri_vol_cdk_parahpallh', 'smri_vol_cdk_parahpalrh', \n",
    "           'smri_vol_cdk_parsobislh', 'smri_vol_cdk_parsobisrh', 'smri_vol_cdk_parsopclh', 'smri_vol_cdk_parsopcrh', \n",
    "           'smri_vol_cdk_parstgrislh', 'smri_vol_cdk_parstgrisrh', 'smri_vol_cdk_pclh', 'smri_vol_cdk_pcrh', \n",
    "           'smri_vol_cdk_pericclh', 'smri_vol_cdk_periccrh', 'smri_vol_cdk_postcnlh', 'smri_vol_cdk_postcnrh', \n",
    "           'smri_vol_cdk_precnlh', 'smri_vol_cdk_precnrh', 'smri_vol_cdk_ptcatelh', 'smri_vol_cdk_ptcaterh', \n",
    "           'smri_vol_cdk_rracatelh', 'smri_vol_cdk_rracaterh', 'smri_vol_cdk_rrmdfrlh', 'smri_vol_cdk_rrmdfrrh', \n",
    "           'smri_vol_cdk_smlh', 'smri_vol_cdk_smrh', 'smri_vol_cdk_sufrlh', 'smri_vol_cdk_sufrrh', \n",
    "           'smri_vol_cdk_supllh', 'smri_vol_cdk_suplrh', 'smri_vol_cdk_sutmlh', 'smri_vol_cdk_sutmrh', \n",
    "           'smri_vol_cdk_tmpolelh', 'smri_vol_cdk_tmpolerh', 'smri_vol_cdk_trvtmlh', 'smri_vol_cdk_trvtmrh']\n",
    "\n",
    "cortthick = [\"smri_thick_cdk_banksstslh\", \"smri_thick_cdk_banksstsrh\", \"smri_thick_cdk_cdacatelh\", \"smri_thick_cdk_cdacaterh\", \n",
    "           \"smri_thick_cdk_cdmdfrlh\", \"smri_thick_cdk_cdmdfrrh\", \"smri_thick_cdk_cuneuslh\", \"smri_thick_cdk_cuneusrh\", \n",
    "           \"smri_thick_cdk_ehinallh\", \"smri_thick_cdk_ehinalrh\", 'smri_thick_cdk_frpolelh', 'smri_thick_cdk_frpolerh', \n",
    "           'smri_thick_cdk_fusiformlh', 'smri_thick_cdk_fusiformrh', 'smri_thick_cdk_ifpllh', 'smri_thick_cdk_ifplrh', \n",
    "           'smri_thick_cdk_iftmlh', 'smri_thick_cdk_iftmrh', 'smri_thick_cdk_ihcatelh', 'smri_thick_cdk_ihcaterh',\n",
    "           'smri_thick_cdk_insulalh', 'smri_thick_cdk_insularh','smri_thick_cdk_linguallh', 'smri_thick_cdk_lingualrh', \n",
    "           'smri_thick_cdk_lobfrlh', 'smri_thick_cdk_lobfrrh', 'smri_thick_cdk_locclh', 'smri_thick_cdk_loccrh',\n",
    "           'smri_thick_cdk_mdtmlh', 'smri_thick_cdk_mdtmrh', 'smri_thick_cdk_mobfrlh', 'smri_thick_cdk_mobfrrh',\n",
    "           'smri_thick_cdk_paracnlh', 'smri_thick_cdk_paracnrh', 'smri_thick_cdk_parahpallh', 'smri_thick_cdk_parahpalrh', \n",
    "           'smri_thick_cdk_parsobislh', 'smri_thick_cdk_parsobisrh', 'smri_thick_cdk_parsopclh', 'smri_thick_cdk_parsopcrh', \n",
    "           'smri_thick_cdk_parstgrislh', 'smri_thick_cdk_parstgrisrh', 'smri_thick_cdk_pclh', 'smri_thick_cdk_pcrh', \n",
    "           'smri_thick_cdk_pericclh', 'smri_thick_cdk_periccrh', 'smri_thick_cdk_postcnlh', 'smri_thick_cdk_postcnrh', \n",
    "           'smri_thick_cdk_precnlh', 'smri_thick_cdk_precnrh', 'smri_thick_cdk_ptcatelh', 'smri_thick_cdk_ptcaterh', \n",
    "           'smri_thick_cdk_rracatelh', 'smri_thick_cdk_rracaterh', 'smri_thick_cdk_rrmdfrlh', 'smri_thick_cdk_rrmdfrrh', \n",
    "           'smri_thick_cdk_smlh', 'smri_thick_cdk_smrh', 'smri_thick_cdk_sufrlh', 'smri_thick_cdk_sufrrh', \n",
    "           'smri_thick_cdk_supllh', 'smri_thick_cdk_suplrh', 'smri_thick_cdk_sutmlh', 'smri_thick_cdk_sutmrh', \n",
    "           'smri_thick_cdk_tmpolelh', 'smri_thick_cdk_tmpolerh', 'smri_thick_cdk_trvtmlh', 'smri_thick_cdk_trvtmrh', \n",
    "           'smri_thick_cdk_meanlh', 'smri_thick_cdk_meanrh', 'smri_thick_cdk_mean']\n",
    "\n",
    "\n",
    "data_elements_of_interest = nested + puberty + scvol + famhx_moth + famhx_fath + famhx_momdad + famhx_parent + qc + piagliaccio + cortvol + cortthick\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the data structures that contain the data elements\n",
    "\n",
    "The `data_elements_of_interest` above tell us what data elements we wish to analyze,\n",
    "but they do not provide information about which data structures the data elements are located.\n",
    "But do not fret, we created `data_elements_df` to match data elements with their respective data structures,\n",
    "giving us the ability to find the data structure associated with each data element of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acspsw03': ['rel_family_id', 'acs_raked_propensity_score', 'race_ethnicity'],\n",
       " 'abcd_mri01': ['mri_info_deviceserialnumber'],\n",
       " 'abcd_lt01': ['site_id_l'],\n",
       " 'abcd_ssphp01': ['pds_p_ss_female_category', 'pds_p_ss_male_category'],\n",
       " 'abcd_smrip201': ['smri_vol_scs_aal',\n",
       "  'smri_vol_scs_aar',\n",
       "  'smri_vol_scs_amygdalalh',\n",
       "  'smri_vol_scs_amygdalarh',\n",
       "  'smri_vol_scs_caudatelh',\n",
       "  'smri_vol_scs_caudaterh',\n",
       "  'smri_vol_scs_hpuslh',\n",
       "  'smri_vol_scs_hpusrh',\n",
       "  'smri_vol_scs_pallidumlh',\n",
       "  'smri_vol_scs_pallidumrh',\n",
       "  'smri_vol_scs_putamenlh',\n",
       "  'smri_vol_scs_putamenrh',\n",
       "  'smri_vol_scs_tplh',\n",
       "  'smri_vol_scs_tprh',\n",
       "  'smri_vol_scs_intracranialv',\n",
       "  'smri_vol_scs_subcorticalgv'],\n",
       " 'abcd_fhxssp01': ['famhx_ss_moth_prob_dprs_p',\n",
       "  'famhx_ss_moth_prob_alc_p',\n",
       "  'famhx_ss_moth_prob_dg_p',\n",
       "  'famhx_ss_moth_prob_ma_p',\n",
       "  'famhx_ss_moth_prob_nrv_p',\n",
       "  'famhx_ss_fath_prob_dprs_p',\n",
       "  'famhx_ss_fath_prob_alc_p',\n",
       "  'famhx_ss_fath_prob_dg_p',\n",
       "  'famhx_ss_fath_prob_ma_p',\n",
       "  'famhx_ss_fath_prob_nrv_p',\n",
       "  'famhx_ss_momdad_dprs_p',\n",
       "  'famhx_ss_momdad_alc_p',\n",
       "  'famhx_ss_momdad_dg_p',\n",
       "  'famhx_ss_momdad_ma_p',\n",
       "  'famhx_ss_momdad_nrv_p',\n",
       "  'famhx_ss_parent_dprs_p',\n",
       "  'famhx_ss_parent_alc_p',\n",
       "  'famhx_ss_parent_dg_p',\n",
       "  'famhx_ss_parent_ma_p',\n",
       "  'famhx_ss_parent_nrv_p',\n",
       "  'famhx_ss_momdad_vs_p'],\n",
       " 'mriqcrp102': ['iqc_t1_ok_ser'],\n",
       " 'freesqc01': ['fsqc_qc'],\n",
       " 'abcd_mrfindings02': ['mrif_score'],\n",
       " 'pdem02': ['demo_prim', 'demo_comb_income_v2', 'demo_prnt_ed_v2'],\n",
       " 'abcd_smrip101': ['smri_vol_cdk_banksstslh',\n",
       "  'smri_vol_cdk_banksstsrh',\n",
       "  'smri_vol_cdk_cdacatelh',\n",
       "  'smri_vol_cdk_cdacaterh',\n",
       "  'smri_vol_cdk_cdmdfrlh',\n",
       "  'smri_vol_cdk_cdmdfrrh',\n",
       "  'smri_vol_cdk_cuneuslh',\n",
       "  'smri_vol_cdk_cuneusrh',\n",
       "  'smri_vol_cdk_ehinallh',\n",
       "  'smri_vol_cdk_ehinalrh',\n",
       "  'smri_vol_cdk_frpolelh',\n",
       "  'smri_vol_cdk_frpolerh',\n",
       "  'smri_vol_cdk_fusiformlh',\n",
       "  'smri_vol_cdk_fusiformrh',\n",
       "  'smri_vol_cdk_ifpllh',\n",
       "  'smri_vol_cdk_ifplrh',\n",
       "  'smri_vol_cdk_iftmlh',\n",
       "  'smri_vol_cdk_iftmrh',\n",
       "  'smri_vol_cdk_ihcatelh',\n",
       "  'smri_vol_cdk_ihcaterh',\n",
       "  'smri_vol_cdk_insulalh',\n",
       "  'smri_vol_cdk_insularh',\n",
       "  'smri_vol_cdk_linguallh',\n",
       "  'smri_vol_cdk_lingualrh',\n",
       "  'smri_vol_cdk_lobfrlh',\n",
       "  'smri_vol_cdk_lobfrrh',\n",
       "  'smri_vol_cdk_locclh',\n",
       "  'smri_vol_cdk_loccrh',\n",
       "  'smri_vol_cdk_mdtmlh',\n",
       "  'smri_vol_cdk_mdtmrh',\n",
       "  'smri_vol_cdk_mobfrlh',\n",
       "  'smri_vol_cdk_mobfrrh',\n",
       "  'smri_vol_cdk_paracnlh',\n",
       "  'smri_vol_cdk_paracnrh',\n",
       "  'smri_vol_cdk_parahpallh',\n",
       "  'smri_vol_cdk_parahpalrh',\n",
       "  'smri_vol_cdk_parsobislh',\n",
       "  'smri_vol_cdk_parsobisrh',\n",
       "  'smri_vol_cdk_parsopclh',\n",
       "  'smri_vol_cdk_parsopcrh',\n",
       "  'smri_vol_cdk_parstgrislh',\n",
       "  'smri_vol_cdk_parstgrisrh',\n",
       "  'smri_vol_cdk_pclh',\n",
       "  'smri_vol_cdk_pcrh',\n",
       "  'smri_vol_cdk_pericclh',\n",
       "  'smri_vol_cdk_periccrh',\n",
       "  'smri_vol_cdk_postcnlh',\n",
       "  'smri_vol_cdk_postcnrh',\n",
       "  'smri_vol_cdk_precnlh',\n",
       "  'smri_vol_cdk_precnrh',\n",
       "  'smri_vol_cdk_ptcatelh',\n",
       "  'smri_vol_cdk_ptcaterh',\n",
       "  'smri_vol_cdk_rracatelh',\n",
       "  'smri_vol_cdk_rracaterh',\n",
       "  'smri_vol_cdk_rrmdfrlh',\n",
       "  'smri_vol_cdk_rrmdfrrh',\n",
       "  'smri_vol_cdk_smlh',\n",
       "  'smri_vol_cdk_smrh',\n",
       "  'smri_vol_cdk_sufrlh',\n",
       "  'smri_vol_cdk_sufrrh',\n",
       "  'smri_vol_cdk_supllh',\n",
       "  'smri_vol_cdk_suplrh',\n",
       "  'smri_vol_cdk_sutmlh',\n",
       "  'smri_vol_cdk_sutmrh',\n",
       "  'smri_vol_cdk_tmpolelh',\n",
       "  'smri_vol_cdk_tmpolerh',\n",
       "  'smri_vol_cdk_trvtmlh',\n",
       "  'smri_vol_cdk_trvtmrh',\n",
       "  'smri_thick_cdk_banksstslh',\n",
       "  'smri_thick_cdk_banksstsrh',\n",
       "  'smri_thick_cdk_cdacatelh',\n",
       "  'smri_thick_cdk_cdacaterh',\n",
       "  'smri_thick_cdk_cdmdfrlh',\n",
       "  'smri_thick_cdk_cdmdfrrh',\n",
       "  'smri_thick_cdk_cuneuslh',\n",
       "  'smri_thick_cdk_cuneusrh',\n",
       "  'smri_thick_cdk_ehinallh',\n",
       "  'smri_thick_cdk_ehinalrh',\n",
       "  'smri_thick_cdk_frpolelh',\n",
       "  'smri_thick_cdk_frpolerh',\n",
       "  'smri_thick_cdk_fusiformlh',\n",
       "  'smri_thick_cdk_fusiformrh',\n",
       "  'smri_thick_cdk_ifpllh',\n",
       "  'smri_thick_cdk_ifplrh',\n",
       "  'smri_thick_cdk_iftmlh',\n",
       "  'smri_thick_cdk_iftmrh',\n",
       "  'smri_thick_cdk_ihcatelh',\n",
       "  'smri_thick_cdk_ihcaterh',\n",
       "  'smri_thick_cdk_insulalh',\n",
       "  'smri_thick_cdk_insularh',\n",
       "  'smri_thick_cdk_linguallh',\n",
       "  'smri_thick_cdk_lingualrh',\n",
       "  'smri_thick_cdk_lobfrlh',\n",
       "  'smri_thick_cdk_lobfrrh',\n",
       "  'smri_thick_cdk_locclh',\n",
       "  'smri_thick_cdk_loccrh',\n",
       "  'smri_thick_cdk_mdtmlh',\n",
       "  'smri_thick_cdk_mdtmrh',\n",
       "  'smri_thick_cdk_mobfrlh',\n",
       "  'smri_thick_cdk_mobfrrh',\n",
       "  'smri_thick_cdk_paracnlh',\n",
       "  'smri_thick_cdk_paracnrh',\n",
       "  'smri_thick_cdk_parahpallh',\n",
       "  'smri_thick_cdk_parahpalrh',\n",
       "  'smri_thick_cdk_parsobislh',\n",
       "  'smri_thick_cdk_parsobisrh',\n",
       "  'smri_thick_cdk_parsopclh',\n",
       "  'smri_thick_cdk_parsopcrh',\n",
       "  'smri_thick_cdk_parstgrislh',\n",
       "  'smri_thick_cdk_parstgrisrh',\n",
       "  'smri_thick_cdk_pclh',\n",
       "  'smri_thick_cdk_pcrh',\n",
       "  'smri_thick_cdk_pericclh',\n",
       "  'smri_thick_cdk_periccrh',\n",
       "  'smri_thick_cdk_postcnlh',\n",
       "  'smri_thick_cdk_postcnrh',\n",
       "  'smri_thick_cdk_precnlh',\n",
       "  'smri_thick_cdk_precnrh',\n",
       "  'smri_thick_cdk_ptcatelh',\n",
       "  'smri_thick_cdk_ptcaterh',\n",
       "  'smri_thick_cdk_rracatelh',\n",
       "  'smri_thick_cdk_rracaterh',\n",
       "  'smri_thick_cdk_rrmdfrlh',\n",
       "  'smri_thick_cdk_rrmdfrrh',\n",
       "  'smri_thick_cdk_smlh',\n",
       "  'smri_thick_cdk_smrh',\n",
       "  'smri_thick_cdk_sufrlh',\n",
       "  'smri_thick_cdk_sufrrh',\n",
       "  'smri_thick_cdk_supllh',\n",
       "  'smri_thick_cdk_suplrh',\n",
       "  'smri_thick_cdk_sutmlh',\n",
       "  'smri_thick_cdk_sutmrh',\n",
       "  'smri_thick_cdk_tmpolelh',\n",
       "  'smri_thick_cdk_tmpolerh',\n",
       "  'smri_thick_cdk_trvtmlh',\n",
       "  'smri_thick_cdk_trvtmrh',\n",
       "  'smri_thick_cdk_meanlh',\n",
       "  'smri_thick_cdk_meanrh',\n",
       "  'smri_thick_cdk_mean']}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures2read = {}\n",
    "for element in data_elements_of_interest:\n",
    "    item = data_elements_df.query(f\"element == '{element}'\").structure.values[0]\n",
    "    if item not in structures2read:\n",
    "        structures2read[item] = []\n",
    "    structures2read[item].append(element)\n",
    "structures2read"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 4. Create a dataframe with the variables of interest\n",
    "Now we have the data structures that contain the data elements of interest in `structures2read`,\n",
    "a dictionary whose keys are the data structures and whose values are the data elements of interest\n",
    "within that data structure.\n",
    "Here we load the data structures into python with the variables (elements) of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = None\n",
    "for structure, elements in structures2read.items():\n",
    "    data_structure_filtered_df = pd.read_table(data_path / f\"{structure}.txt\", skiprows=[1], low_memory=False, usecols=common + elements)\n",
    "    data_structure_filtered_df = data_structure_filtered_df.query(\"eventname == 'baseline_year_1_arm_1'\")\n",
    "    if all_df is None:\n",
    "        all_df =  data_structure_filtered_df[[\"subjectkey\", \"interview_date\", \"interview_age\", \"sex\", \"eventname\"] + elements]\n",
    "    else:\n",
    "        all_df = all_df.merge( data_structure_filtered_df[['subjectkey'] + elements], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11883, 194), (11878,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape, all_df.subjectkey.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 5. Remove duplicates and apply exclusion criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11878, 194), (11878,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "all_df = all_df.drop_duplicates(subset=['subjectkey'])\n",
    "all_df.shape, all_df.subjectkey.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11878, 194)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy dataframe/backup\n",
    "df1 = all_df.copy()\n",
    "df1.shape #output is number of children x number of variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Exclusion criteria \n",
    "1. iqc_t1_ok_ser: quality T1 scans == 0 \n",
    "1. fsqc_qc: quality control freesurfer outputs. 0 = reject; 1 = accept\n",
    "1. mrif_score: incidental findings from neuroradiological read of the sMRI. 0 = reject; 1 = accept\n",
    "1. demo_prim: if parental report was not based on biological parent. Exclude value >2\n",
    "1. If either parent endorsed visions of others spying/plotting problems. Exclude value == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count subjects that will be excluded per variable for method section\n",
    "(df1['iqc_t1_ok_ser'] == 0).astype(int).sum(axis=0)        #40 subjects\n",
    "(df1['fsqc_qc'] == 0).astype(int).sum(axis=0)              #475 subjects\n",
    "(df1['mrif_score'] ==0).astype(int).sum(axis=0)            #47\n",
    "(df1['demo_prim'] > 2).astype(int).sum(axis=0)             #560 subjects\n",
    "(df1['famhx_ss_momdad_vs_p'] == 1).astype(int).sum(axis=0) #241 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10589, 194)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove rows that fullfill at least 1 of the exclusion criteria\n",
    "indexNames = df1[(df1['iqc_t1_ok_ser'] == 0) | (df1['fsqc_qc'] == 0) | (df1['mrif_score'] == 0) | (df1['demo_prim'] > 2) | (df1['famhx_ss_momdad_vs_p'] == 1)].index   \n",
    "df1.drop(indexNames , inplace=True)    # Delete these row indexes from dataFrame\n",
    "df1.shape #output = number of children x number of variables\n",
    "\n",
    "#copy/backup\n",
    "df2 = df1.copy()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### 6. Create addiction variables based on alcohol and drug abuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['famhx_ss_moth_addiction'] = np.where((df2.famhx_ss_moth_prob_alc_p == 1) | (df2.famhx_ss_moth_prob_dg_p == 1), 1.0, 0.0)\n",
    "df2['famhx_ss_fath_addiction'] = np.where((df2.famhx_ss_fath_prob_alc_p == 1) | (df2.famhx_ss_fath_prob_dg_p == 1), 1.0, 0.0)\n",
    "df2['famhx_ss_momdad_addiction'] = np.where((df2.famhx_ss_momdad_alc_p == 1) | (df2.famhx_ss_momdad_dg_p == 1), 1.0, 0.0)\n",
    "\n",
    "# Not sure how to code the famhx_ss_parent_addiction with 6 different values (in particularly the negative values) \n",
    "# For now I created a binary variable that shows whether both parents have a problem or not.\n",
    "df2['famhx_ss_parent_addiction_bin'] = np.where((df2.famhx_ss_parent_alc_p == 3) | (df2.famhx_ss_parent_dg_p == 3), 1.0, 0.0) #both parent have addiction problem (0 = no, 1 = yes)\n",
    "df2['famhx_ss_parent_dprs_bin'] = np.where((df2.famhx_ss_parent_dprs_p == 3), 1.0, 0.0)\n",
    "df2['famhx_ss_parent_ma_bin'] = np.where((df2.famhx_ss_parent_ma_p == 3), 1.0, 0.0)\n",
    "df2['famhx_ss_parent_nrv_bin'] = np.where((df2.famhx_ss_parent_nrv_p == 3), 1.0, 0.0)\n",
    "\n",
    "#explore addiction counts\n",
    "s1 = df2.groupby(['famhx_ss_moth_addiction', 'famhx_ss_moth_prob_alc_p', 'famhx_ss_moth_prob_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction mother\n",
    "s2 = df2.groupby(['famhx_ss_fath_addiction', 'famhx_ss_fath_prob_alc_p', 'famhx_ss_fath_prob_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction father\n",
    "s3 = df2.groupby(['famhx_ss_momdad_addiction', 'famhx_ss_momdad_alc_p', 'famhx_ss_momdad_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction either mother or father\n",
    "s4 = df2.groupby(['famhx_ss_parent_addiction_bin', 'famhx_ss_parent_alc_p', 'famhx_ss_parent_dg_p']).size().reset_index().rename(columns={0:'count'})  #addiction both parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_moth_addiction</th>\n",
       "      <th>famhx_ss_moth_prob_alc_p</th>\n",
       "      <th>famhx_ss_moth_prob_dg_p</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   famhx_ss_moth_addiction  famhx_ss_moth_prob_alc_p  famhx_ss_moth_prob_dg_p  \\\n",
       "0                      0.0                       0.0                      0.0   \n",
       "1                      1.0                       0.0                      1.0   \n",
       "2                      1.0                       1.0                      0.0   \n",
       "3                      1.0                       1.0                      1.0   \n",
       "\n",
       "   count  \n",
       "0   7706  \n",
       "1   2079  \n",
       "2    147  \n",
       "3    165  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 #view count table - insert s1-s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data - note that this file contains many variables that are not needed for the LMM. \n",
    "#copy/backup and remove variable columns we do not need anymore including 'famhx_ss_*_alc_p', 'famhx_ss_*_dg_p'])\n",
    "df3 = df2.copy()\n",
    "df3.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/PsychRisk_data.tsv\", sep=\"\\t\", index=None)# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Exploration number of children in each parental history psychopathology group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that are no longer needed including alcohol and drug abuse history and quality control variables\n",
    "df3 = df3.drop(columns=['famhx_ss_moth_prob_alc_p', 'famhx_ss_fath_prob_alc_p', 'famhx_ss_momdad_alc_p', 'famhx_ss_parent_alc_p', \n",
    "                  'famhx_ss_moth_prob_dg_p', 'famhx_ss_fath_prob_dg_p', 'famhx_ss_momdad_dg_p', 'famhx_ss_parent_dg_p',\n",
    "                 'famhx_ss_momdad_vs_p', 'iqc_t1_ok_ser', 'fsqc_qc', 'demo_prim', 'mrif_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_moth_prob_dprs_p</th>\n",
       "      <th>famhx_ss_moth_prob_ma_p</th>\n",
       "      <th>famhx_ss_moth_prob_nrv_p</th>\n",
       "      <th>famhx_ss_fath_prob_dprs_p</th>\n",
       "      <th>famhx_ss_fath_prob_ma_p</th>\n",
       "      <th>famhx_ss_fath_prob_nrv_p</th>\n",
       "      <th>famhx_ss_momdad_dprs_p</th>\n",
       "      <th>famhx_ss_momdad_ma_p</th>\n",
       "      <th>famhx_ss_momdad_nrv_p</th>\n",
       "      <th>famhx_ss_parent_dprs_p</th>\n",
       "      <th>famhx_ss_parent_ma_p</th>\n",
       "      <th>famhx_ss_parent_nrv_p</th>\n",
       "      <th>famhx_ss_moth_addiction</th>\n",
       "      <th>famhx_ss_fath_addiction</th>\n",
       "      <th>famhx_ss_momdad_addiction</th>\n",
       "      <th>famhx_ss_parent_addiction_bin</th>\n",
       "      <th>famhx_ss_parent_dprs_bin</th>\n",
       "      <th>famhx_ss_parent_ma_bin</th>\n",
       "      <th>famhx_ss_parent_nrv_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10154.0</td>\n",
       "      <td>10098.0</td>\n",
       "      <td>9443.0</td>\n",
       "      <td>9527.0</td>\n",
       "      <td>10012.0</td>\n",
       "      <td>9714.0</td>\n",
       "      <td>9421.0</td>\n",
       "      <td>9866.0</td>\n",
       "      <td>9114.0</td>\n",
       "      <td>9421</td>\n",
       "      <td>9866</td>\n",
       "      <td>9114</td>\n",
       "      <td>8160.0</td>\n",
       "      <td>8400.0</td>\n",
       "      <td>6873.0</td>\n",
       "      <td>9880.0</td>\n",
       "      <td>10465.0</td>\n",
       "      <td>10570.0</td>\n",
       "      <td>10433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>240.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>795.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>444.0</td>\n",
       "      <td>911.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>1102.0</td>\n",
       "      <td>662</td>\n",
       "      <td>200</td>\n",
       "      <td>285</td>\n",
       "      <td>2429.0</td>\n",
       "      <td>2189.0</td>\n",
       "      <td>3716.0</td>\n",
       "      <td>709.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>144</td>\n",
       "      <td>593</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      famhx_ss_moth_prob_dprs_p  famhx_ss_moth_prob_ma_p  \\\n",
       "-2.0                        NaN                      NaN   \n",
       "-1.0                        NaN                      NaN   \n",
       " 0.0                    10154.0                  10098.0   \n",
       " 1.0                      240.0                    181.0   \n",
       " 2.0                        NaN                      NaN   \n",
       " 3.0                        NaN                      NaN   \n",
       "\n",
       "      famhx_ss_moth_prob_nrv_p  famhx_ss_fath_prob_dprs_p  \\\n",
       "-2.0                       NaN                        NaN   \n",
       "-1.0                       NaN                        NaN   \n",
       " 0.0                    9443.0                     9527.0   \n",
       " 1.0                     814.0                      795.0   \n",
       " 2.0                       NaN                        NaN   \n",
       " 3.0                       NaN                        NaN   \n",
       "\n",
       "      famhx_ss_fath_prob_ma_p  famhx_ss_fath_prob_nrv_p  \\\n",
       "-2.0                      NaN                       NaN   \n",
       "-1.0                      NaN                       NaN   \n",
       " 0.0                  10012.0                    9714.0   \n",
       " 1.0                    225.0                     444.0   \n",
       " 2.0                      NaN                       NaN   \n",
       " 3.0                      NaN                       NaN   \n",
       "\n",
       "      famhx_ss_momdad_dprs_p  famhx_ss_momdad_ma_p  famhx_ss_momdad_nrv_p  \\\n",
       "-2.0                     NaN                   NaN                    NaN   \n",
       "-1.0                     NaN                   NaN                    NaN   \n",
       " 0.0                  9421.0                9866.0                 9114.0   \n",
       " 1.0                   911.0                 387.0                 1102.0   \n",
       " 2.0                     NaN                   NaN                    NaN   \n",
       " 3.0                     NaN                   NaN                    NaN   \n",
       "\n",
       "      famhx_ss_parent_dprs_p  famhx_ss_parent_ma_p  famhx_ss_parent_nrv_p  \\\n",
       "-2.0                       9                     6                      3   \n",
       "-1.0                      14                    18                     65   \n",
       " 0.0                    9421                  9866                   9114   \n",
       " 1.0                     662                   200                    285   \n",
       " 2.0                     102                   144                    593   \n",
       " 3.0                     124                    19                    156   \n",
       "\n",
       "      famhx_ss_moth_addiction  famhx_ss_fath_addiction  \\\n",
       "-2.0                      NaN                      NaN   \n",
       "-1.0                      NaN                      NaN   \n",
       " 0.0                   8160.0                   8400.0   \n",
       " 1.0                   2429.0                   2189.0   \n",
       " 2.0                      NaN                      NaN   \n",
       " 3.0                      NaN                      NaN   \n",
       "\n",
       "      famhx_ss_momdad_addiction  famhx_ss_parent_addiction_bin  \\\n",
       "-2.0                        NaN                            NaN   \n",
       "-1.0                        NaN                            NaN   \n",
       " 0.0                     6873.0                         9880.0   \n",
       " 1.0                     3716.0                          709.0   \n",
       " 2.0                        NaN                            NaN   \n",
       " 3.0                        NaN                            NaN   \n",
       "\n",
       "      famhx_ss_parent_dprs_bin  famhx_ss_parent_ma_bin  \\\n",
       "-2.0                       NaN                     NaN   \n",
       "-1.0                       NaN                     NaN   \n",
       " 0.0                   10465.0                 10570.0   \n",
       " 1.0                     124.0                    19.0   \n",
       " 2.0                       NaN                     NaN   \n",
       " 3.0                       NaN                     NaN   \n",
       "\n",
       "      famhx_ss_parent_nrv_bin  \n",
       "-2.0                      NaN  \n",
       "-1.0                      NaN  \n",
       " 0.0                  10433.0  \n",
       " 1.0                    156.0  \n",
       " 2.0                      NaN  \n",
       " 3.0                      NaN  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count data\n",
    "filter_col = [col for col in df3 if col.startswith('famhx_')]\n",
    "fh_df = df3[filter_col] #create dataframe with parental history psychopathology variables          \n",
    "fh_df.apply(pd.Series.value_counts)        #counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count data and comorbidities\n",
    "t1 = fh_df.groupby(['famhx_ss_moth_prob_dprs_p', 'famhx_ss_moth_addiction','famhx_ss_moth_prob_ma_p', 'famhx_ss_moth_prob_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t2 = fh_df.groupby(['famhx_ss_fath_prob_dprs_p', 'famhx_ss_fath_addiction','famhx_ss_fath_prob_ma_p', 'famhx_ss_fath_prob_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t3 = fh_df.groupby(['famhx_ss_momdad_dprs_p', 'famhx_ss_momdad_addiction','famhx_ss_momdad_ma_p', 'famhx_ss_momdad_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "t4 = fh_df.groupby(['famhx_ss_parent_dprs_p', 'famhx_ss_parent_addiction_bin','famhx_ss_parent_ma_p', 'famhx_ss_parent_nrv_p']).size().reset_index().rename(columns={0:'count'})  #pathology mother\n",
    "\n",
    "#uncomment to save file to .csv\n",
    "#t1.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_mother.csv')\n",
    "#t2.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_father.csv')\n",
    "#t3.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_momdad.csv')\n",
    "#t4.to_csv('/shared/project-psychopathology-risk/outputs/exploration/count_parents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>famhx_ss_momdad_dprs_p</th>\n",
       "      <th>famhx_ss_momdad_addiction</th>\n",
       "      <th>famhx_ss_momdad_ma_p</th>\n",
       "      <th>famhx_ss_momdad_nrv_p</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    famhx_ss_momdad_dprs_p  famhx_ss_momdad_addiction  famhx_ss_momdad_ma_p  \\\n",
       "0                      0.0                        0.0                   0.0   \n",
       "1                      0.0                        0.0                   0.0   \n",
       "2                      0.0                        0.0                   1.0   \n",
       "3                      0.0                        0.0                   1.0   \n",
       "4                      0.0                        1.0                   0.0   \n",
       "5                      0.0                        1.0                   0.0   \n",
       "6                      0.0                        1.0                   1.0   \n",
       "7                      0.0                        1.0                   1.0   \n",
       "8                      1.0                        0.0                   0.0   \n",
       "9                      1.0                        0.0                   0.0   \n",
       "10                     1.0                        0.0                   1.0   \n",
       "11                     1.0                        0.0                   1.0   \n",
       "12                     1.0                        1.0                   0.0   \n",
       "13                     1.0                        1.0                   0.0   \n",
       "14                     1.0                        1.0                   1.0   \n",
       "15                     1.0                        1.0                   1.0   \n",
       "\n",
       "    famhx_ss_momdad_nrv_p  count  \n",
       "0                     0.0   6024  \n",
       "1                     1.0    225  \n",
       "2                     0.0     34  \n",
       "3                     1.0      9  \n",
       "4                     0.0   2104  \n",
       "5                     1.0    510  \n",
       "6                     0.0     92  \n",
       "7                     1.0     88  \n",
       "8                     0.0    176  \n",
       "9                     1.0     10  \n",
       "10                    0.0      6  \n",
       "11                    1.0      2  \n",
       "12                    0.0    359  \n",
       "13                    1.0    132  \n",
       "14                    0.0     75  \n",
       "15                    1.0     60  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 #print table t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subjectkey</th>\n",
       "      <th>interview_date</th>\n",
       "      <th>interview_age</th>\n",
       "      <th>sex</th>\n",
       "      <th>eventname</th>\n",
       "      <th>rel_family_id</th>\n",
       "      <th>acs_raked_propensity_score</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>mri_info_deviceserialnumber</th>\n",
       "      <th>site_id_l</th>\n",
       "      <th>...</th>\n",
       "      <th>famhx_ss_parent_nrv_p</th>\n",
       "      <th>demo_comb_income_v2</th>\n",
       "      <th>demo_prnt_ed_v2</th>\n",
       "      <th>famhx_ss_moth_addiction</th>\n",
       "      <th>famhx_ss_fath_addiction</th>\n",
       "      <th>famhx_ss_momdad_addiction</th>\n",
       "      <th>famhx_ss_parent_addiction_bin</th>\n",
       "      <th>famhx_ss_parent_dprs_bin</th>\n",
       "      <th>famhx_ss_parent_ma_bin</th>\n",
       "      <th>famhx_ss_parent_nrv_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10589</td>\n",
       "      <td>10589</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589</td>\n",
       "      <td>10589</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10587.000000</td>\n",
       "      <td>10341</td>\n",
       "      <td>10589</td>\n",
       "      <td>...</td>\n",
       "      <td>10216.000000</td>\n",
       "      <td>10587.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "      <td>10589.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>10589</td>\n",
       "      <td>754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NDAR_INVDB6W7NT0</td>\n",
       "      <td>11/18/2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>baseline_year_1_arm_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HASH3935c89e</td>\n",
       "      <td>site16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5538</td>\n",
       "      <td>10589</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>935</td>\n",
       "      <td>955</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.065540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5944.822552</td>\n",
       "      <td>685.498023</td>\n",
       "      <td>2.008407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182850</td>\n",
       "      <td>81.353358</td>\n",
       "      <td>17.504580</td>\n",
       "      <td>0.229389</td>\n",
       "      <td>0.206724</td>\n",
       "      <td>0.350930</td>\n",
       "      <td>0.066956</td>\n",
       "      <td>0.011710</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.014732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.492223</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3428.885989</td>\n",
       "      <td>344.970486</td>\n",
       "      <td>1.312580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609633</td>\n",
       "      <td>246.583901</td>\n",
       "      <td>25.729605</td>\n",
       "      <td>0.420460</td>\n",
       "      <td>0.404975</td>\n",
       "      <td>0.477284</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>0.107584</td>\n",
       "      <td>0.042323</td>\n",
       "      <td>0.120485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>161.361068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3014.000000</td>\n",
       "      <td>445.893536</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5923.000000</td>\n",
       "      <td>615.414854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8926.000000</td>\n",
       "      <td>810.157122</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11881.000000</td>\n",
       "      <td>1778.916737</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              subjectkey interview_date  interview_age    sex  \\\n",
       "count              10589          10589   10589.000000  10589   \n",
       "unique             10589            754            NaN      2   \n",
       "top     NDAR_INVDB6W7NT0     11/18/2017            NaN      M   \n",
       "freq                   1             38            NaN   5538   \n",
       "mean                 NaN            NaN     119.065540    NaN   \n",
       "std                  NaN            NaN       7.492223    NaN   \n",
       "min                  NaN            NaN     107.000000    NaN   \n",
       "25%                  NaN            NaN     112.000000    NaN   \n",
       "50%                  NaN            NaN     119.000000    NaN   \n",
       "75%                  NaN            NaN     126.000000    NaN   \n",
       "max                  NaN            NaN     133.000000    NaN   \n",
       "\n",
       "                    eventname  rel_family_id  acs_raked_propensity_score  \\\n",
       "count                   10589   10589.000000                10589.000000   \n",
       "unique                      1            NaN                         NaN   \n",
       "top     baseline_year_1_arm_1            NaN                         NaN   \n",
       "freq                    10589            NaN                         NaN   \n",
       "mean                      NaN    5944.822552                  685.498023   \n",
       "std                       NaN    3428.885989                  344.970486   \n",
       "min                       NaN       1.000000                  161.361068   \n",
       "25%                       NaN    3014.000000                  445.893536   \n",
       "50%                       NaN    5923.000000                  615.414854   \n",
       "75%                       NaN    8926.000000                  810.157122   \n",
       "max                       NaN   11881.000000                 1778.916737   \n",
       "\n",
       "        race_ethnicity mri_info_deviceserialnumber site_id_l  ...  \\\n",
       "count     10587.000000                       10341     10589  ...   \n",
       "unique             NaN                          29        22  ...   \n",
       "top                NaN                HASH3935c89e    site16  ...   \n",
       "freq               NaN                         935       955  ...   \n",
       "mean          2.008407                         NaN       NaN  ...   \n",
       "std           1.312580                         NaN       NaN  ...   \n",
       "min           1.000000                         NaN       NaN  ...   \n",
       "25%           1.000000                         NaN       NaN  ...   \n",
       "50%           1.000000                         NaN       NaN  ...   \n",
       "75%           3.000000                         NaN       NaN  ...   \n",
       "max           5.000000                         NaN       NaN  ...   \n",
       "\n",
       "        famhx_ss_parent_nrv_p  demo_comb_income_v2  demo_prnt_ed_v2  \\\n",
       "count            10216.000000         10587.000000     10589.000000   \n",
       "unique                    NaN                  NaN              NaN   \n",
       "top                       NaN                  NaN              NaN   \n",
       "freq                      NaN                  NaN              NaN   \n",
       "mean                 0.182850            81.353358        17.504580   \n",
       "std                  0.609633           246.583901        25.729605   \n",
       "min                 -2.000000             1.000000         1.000000   \n",
       "25%                  0.000000             6.000000        15.000000   \n",
       "50%                  0.000000             8.000000        18.000000   \n",
       "75%                  0.000000             9.000000        19.000000   \n",
       "max                  3.000000           999.000000       777.000000   \n",
       "\n",
       "        famhx_ss_moth_addiction  famhx_ss_fath_addiction  \\\n",
       "count              10589.000000             10589.000000   \n",
       "unique                      NaN                      NaN   \n",
       "top                         NaN                      NaN   \n",
       "freq                        NaN                      NaN   \n",
       "mean                   0.229389                 0.206724   \n",
       "std                    0.420460                 0.404975   \n",
       "min                    0.000000                 0.000000   \n",
       "25%                    0.000000                 0.000000   \n",
       "50%                    0.000000                 0.000000   \n",
       "75%                    0.000000                 0.000000   \n",
       "max                    1.000000                 1.000000   \n",
       "\n",
       "        famhx_ss_momdad_addiction  famhx_ss_parent_addiction_bin  \\\n",
       "count                10589.000000                   10589.000000   \n",
       "unique                        NaN                            NaN   \n",
       "top                           NaN                            NaN   \n",
       "freq                          NaN                            NaN   \n",
       "mean                     0.350930                       0.066956   \n",
       "std                      0.477284                       0.249958   \n",
       "min                      0.000000                       0.000000   \n",
       "25%                      0.000000                       0.000000   \n",
       "50%                      0.000000                       0.000000   \n",
       "75%                      1.000000                       0.000000   \n",
       "max                      1.000000                       1.000000   \n",
       "\n",
       "        famhx_ss_parent_dprs_bin  famhx_ss_parent_ma_bin  \\\n",
       "count               10589.000000            10589.000000   \n",
       "unique                       NaN                     NaN   \n",
       "top                          NaN                     NaN   \n",
       "freq                         NaN                     NaN   \n",
       "mean                    0.011710                0.001794   \n",
       "std                     0.107584                0.042323   \n",
       "min                     0.000000                0.000000   \n",
       "25%                     0.000000                0.000000   \n",
       "50%                     0.000000                0.000000   \n",
       "75%                     0.000000                0.000000   \n",
       "max                     1.000000                1.000000   \n",
       "\n",
       "        famhx_ss_parent_nrv_bin  \n",
       "count              10589.000000  \n",
       "unique                      NaN  \n",
       "top                         NaN  \n",
       "freq                        NaN  \n",
       "mean                   0.014732  \n",
       "std                    0.120485  \n",
       "min                    0.000000  \n",
       "25%                    0.000000  \n",
       "50%                    0.000000  \n",
       "75%                    0.000000  \n",
       "max                    1.000000  \n",
       "\n",
       "[11 rows x 48 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Save clean dataframe for Linear Mixed Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"/shared/project-psychopathology-risk/outputs/exploration/PsychRisk3.tsv\", sep=\"\\t\", index=None) #input LMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
